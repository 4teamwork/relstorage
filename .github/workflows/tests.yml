###
# Initially copied from
# https://github.com/actions/starter-workflows/blob/main/ci/python-package.yml
# And later based on the version I (jamadden) updated at gevent/gevent
#
# Original comment follows.
###
###
# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions
###

###
# Important notes on GitHub actions:
#
# - We only get 2,000 free minutes a month (private repos)
# - We only get 500MB of artifact storage
# - Cache storage is limited to 7 days and 5GB.
# - macOS minutes are 10x as expensive as Linux minutes
# - windows minutes are twice as expensive.
#
# So keep those workflows light.
#
# In December 2020, github only supports x86/64. If we wanted to test
# on other architectures, we can use docker emulation, but there's no
# native support.
#
# Another major downside: You can't just re-run the job for one part
# of the matrix. So if there's a transient test failure that hit, say, 3.8,
# to get a clean run every version of Python runs again. That's bad.
# https://github.community/t/ability-to-rerun-just-a-single-job-in-a-workflow/17234/65

name: tests


# Triggers the workflow on push or pull request events
on: [push, pull_request]
# Limiting to particular branches might be helpful to conserve minutes.
#on:
  # push:
  #   branches: [ $default-branch ]
  # pull_request:
  #   branches: [ $default-branch ]

env:
  # Weirdly, this has to be a top-level key, not ``defaults.env``
  PYTHONHASHSEED: 8675309
  PYTHONUNBUFFERED: 1
  PYTHONDONTWRITEBYTECODE: 1
  # PYTHONDEVMODE leads to crashes in pylibmc.
  # See https://github.com/lericson/pylibmc/issues/254
  # - PYTHONDEVMODE=1
  PYTHONFAULTHANDLER: 1

  PIP_UPGRADE_STRATEGY: eager
  # Don't get warnings about Python 2 support being deprecated. We
  # know. The env var works for pip 20.
  PIP_NO_PYTHON_VERSION_WARNING: 1
  PIP_NO_WARN_SCRIPT_LOCATION: 1

  # Disable some warnings produced by libev especially and also some Cython generated code.
  # These are shared between GCC and clang so it must be a minimal set.
  # TODO: Figure out how to set env vars per platform without resorting to inline scripting.
  CFLAGS: -Ofast -pipe
  CXXFLAGS: -Ofast -pipe
  # Uploading built wheels for releases.
  # TWINE_PASSWORD is encrypted and stored directly in the
  # travis repo settings.
  TWINE_USERNAME: __token__
  RS_TEST_CMD: "-m zope.testrunner --test-path=src --auto-color --auto-progress -v --slow-test=3"

  ###
  # caching
  ###
  CCACHE_DIR: ~/.ccache
  CC: "ccache gcc"
  CCACHE_NOCPP2: true
  CCACHE_SLOPPINESS: file_macro,time_macros,include_file_ctime,include_file_mtime
  CCACHE_NOHASHDIR: true

  #


jobs:

  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        python-version: [2.7, pypy-2.7, pypy-3.6, 3.6, 3.7, 3.8, 3.9]
        os: [ubuntu-latest, macos-latest]
        exclude:
          - os: macos-latest
            python-version: pypy-2.7
          - os: macos-latest
            python-version: pypy-3.6
          - os: macos-latest
            python-version: 3.5
          - os: macos-latest
            python-version: 3.6

    steps:
      - name: checkout
        uses: actions/checkout@v2
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install ccache, configure CFLAGS (ubuntu)
        if: startsWith(runner.os, 'Linux')
        run: |
          sudo apt-get install -y ccache libmemcached-dev
          echo CFLAGS=$CFLAGS -std=gnu++11 >> $GITHUB_ENV
          echo CXXFLAGS=$CXXCFLAGS -std=gnu++11 >> $GITHUB_ENV
      - name: Install ccache, configure CFLAGS (macos)
        if: startsWith(runner.os, 'macOS')
        run: |
          brew install ccache
          echo CFLAGS=$CFLAGS -Wno-parentheses-equality -Wno-constant-logical-operand >> $GITHUB_ENV
          echo CXXFLAGS=$CXXFLAGS -Wno-parentheses-equality -Wno-constant-logical-operand >> $GITHUB_ENV
          echo CC=ccache /usr/bin/clang >> $GITHUB_ENV
          echo CXX=ccache /usr/bin/clang++ >> $GITHUB_ENV
          echo LDCXXSHARED=ccache /usr/bin/clang -bundle -undefined dynamic_lookup >> $GITHUB_ENV
          echo LDSHARED=ccache /usr/bin/clang -bundle -undefined dynamic_lookup >> $GITHUB_ENV
      - name: Install database clients
        if: startsWith(runner.os, 'macOS')
        # These are necessary to build binary drivers.
        # "mysql" contains the client libraries, not "mysql-client"
        # openssl is needed to build psycopg2 (-lssl) and isn't linked
        # into /usr/local/lib as of 1.1
        run: |
          brew install mysql
          brew services start mysql
          brew install postgresql
          brew services start postgresql
          brew install libmemcached
          brew install openssl
          echo LDFLAGS=$LDFLAGS -L/usr/local/opt/openssl@1.1/lib >> $GITHUB_ENV
          echo CPPFLAGS=$CPPFLAGS -I/usr/local/opt/openssl@1.1/include >> $GITHUB_ENV
      - name: Initialize Test Databases
        # Just macOS now because that's all that I have set up for sure
        if: startsWith(runner.os, 'macOS')
        run: |
          # Wait for them to start up.
          sleep 30
          ps -eaf
          bash .travis/mysql.sh
          bash .travis/postgres.sh
      ###
      # Caching.
      # This actually *restores* a cache and schedules a cleanup action
      # to save the cache. So it must come before the thing we want to use
      # the cache.
      ###
      - name: Cache ~/.ccache
        uses: actions/cache@v2
        with:
          path: ~/.ccache/
          key: ${{ runner.os }}-ccache2-${{ matrix.python-version }}

      - name: Get pip cache dir
        id: pip-cache
        run: |
          echo "::set-output name=dir::$(pip cache dir)"

      - name: pip cache
        uses: actions/cache@v2
        with:
          path: ${{ steps.pip-cache.outputs.dir }}
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          pip install -U pip
          pip install -U -q setuptools wheel twine
          pip install -q -U 'faulthandler; python_version == "2.7" and platform_python_implementation == "CPython"'
          pip install -q -U 'cython>=3.0a6' coverage
          pip install 'greenlet>=1.0a1;platform_python_implementation=="CPython"'

      - name: Build RelStorage
        run: |
          # Next, build the wheel *in place*. This helps ccache, and also lets us cache the configure
          # output (pip install uses a random temporary directory, making this difficult)
          python setup.py build_ext -i
          python setup.py bdist_wheel

      - name: Check RelStorage build
        run: |
          ls -l dist
          twine check dist/*
      - name: Upload RelStorage wheel
        uses: actions/upload-artifact@v2
        with:
          name: RelStorage-${{ runner.os }}-${{ matrix.python-version }}.whl
          path: dist/*whl
      - name: Publish package to PyPI (mac)
        # We cannot 'uses: pypa/gh-action-pypi-publish@v1.4.1' because
        # that's apparently a container action, and those don't run on
        # the Mac.
        if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags') && startsWith(runner.os, 'Mac')
        env:
          TWINE_PASSWORD: ${{ secrets.TWINE_PASSWORD }}
        run: |
          twine upload --skip-existing dist/*

      - name: Install RelStorage
        # I'd prefer to install the wheel in non-editable mode, but that seems to
        # screw up coverage reporting.
        run: |
          pip install -U -e ".[test,all_tested_drivers]"

      - name: Lint (Python 3.9)
        if: matrix.python-version == 3.9 && startsWith(runner.os, 'Linux')
        # We only need to do this on one version, and it should be Python 3, because
        # pylint has stopped updating for Python 2.
        # We do this here rather than a separate job to avoid the compilation overhead.
        # TODO: Revisit this when we have caching of that part.
        run: |
          pip install -U pylint
          python -m pylint --limit-inference-results=1 --rcfile=.pylintrc relstorage -f parseable -r n
      - name: "Tests: Coverage on CPython"
        if: ${{ !startsWith(matrix.python-version, 'pypy')  }}
        run: |
          coverage run -p --concurrency=greenlet .travis/zope_testrunner_gevent.py -t checkBTreesLengthStress -t check7 -t check2 -t BlobCache -t Switches --layer gevent
          coverage run -p --concurrency=thread $RS_TEST_CMD --layer "!gevent"
      - name: "Tests: PyPy"
        if: ${{ startsWith(matrix.python-version, 'pypy')  }}
        run: |
          python $RS_TEST_CMD --layer "!gevent"
      - name: "Test: No zope.schema"
        # Make sure we can import without zope.schema, which is intended to
        # be a test dependency, and optional for production
        run: |
         pip uninstall -y zope.schema && python -c 'import relstorage.interfaces, relstorage.adapters.interfaces, relstorage.cache.interfaces'

      - name: Report coverage
        if: ${{ !startsWith(matrix.python-version, 'pypy')  }}
        run: |
          python -m coverage combine || true
          python -m coverage report -i || true
      - name: Submit to Coveralls
        # This is a container action, which only runs on Linux.
        if: ${{ !startsWith(matrix.python-version, 'pypy') && startsWith(runner.os, 'Linux') }}
        uses: AndreMiras/coveralls-python-action@develop
        with:
          parallel: true

  coveralls_finish:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - name: Coveralls Finished
      uses: AndreMiras/coveralls-python-action@develop
      with:
        parallel-finished: true


  # manylinux_x86_64:
  #   runs-on: ubuntu-latest
  #   # We use a regular Python matrix entry to share as much code as possible.
  #   strategy:
  #     matrix:
  #       python-version: [3.9]

  #   steps:
  #     - name: checkout
  #       uses: actions/checkout@v2
  #     - name: Set up Python ${{ matrix.python-version }}
  #       uses: actions/setup-python@v2
  #       with:
  #         python-version: ${{ matrix.python-version }}
  #     - name: Cache ~/.ccache
  #       uses: actions/cache@v2
  #       with:
  #         path: ~/.ccache/
  #         key: ${{ runner.os }}-ccache_manylinux2-${{ matrix.python-version }}
  #     - name: Get pip cache dir
  #       id: pip-cache
  #       run: |
  #         echo "::set-output name=dir::$(pip cache dir)"

  #     - name: pip cache
  #       uses: actions/cache@v2
  #       with:
  #         path: ${{ steps.pip-cache.outputs.dir }}
  #         key: ${{ runner.os }}-pip_manylinux_x8664-${{ matrix.python-version }}
  #         restore-keys: |
  #           ${{ runner.os }}-pip-

  #     - name: Update pip
  #       run: pip install -U pip
  #     - name: Build and test gevent
  #       # An alternate way to do this is to run the container directly with a uses:
  #       # and then the script runs inside it. That may work better with caching.
  #       # See https://github.com/pyca/bcrypt/blob/f6b5ee2eda76d077c531362ac65e16f045cf1f29/.github/workflows/wheel-builder.yml
  #       # The 2010 image is the last one that comes with Python 2.7.
  #       env:
  #         DOCKER_IMAGE: quay.io/pypa/manylinux2010_x86_64
  #       run: scripts/releases/make-manylinux
  #     - name: Upload gevent wheels
  #       uses: actions/upload-artifact@v2
  #       with:
  #         path: wheelhouse/*whl
  #         name: manylinux_x86_64_wheels.zip
  #     - name: Restore pip cache permissions
  #       run: sudo chown -R $(whoami) ${{ steps.pip-cache.outputs.dir }}
  #     - name: Publish package to PyPI
  #       uses: pypa/gh-action-pypi-publish@v1.4.1
  #       if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags')
  #       with:
  #         user: __token__
  #         password: ${{ secrets.TWINE_PASSWORD }}
  #         skip_existing: true
  #         packages_dir: wheelhouse/


# TODO:
# * Use YAML syntax to share snippets, like the old .travis.yml did
